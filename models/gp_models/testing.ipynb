{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Optional, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from scipy.cluster.vq import kmeans2\n",
    "\n",
    "import gpflow\n",
    "from gpflow.ci_utils import reduce_in_tests\n",
    "from gpflow.utilities import to_default_float\n",
    "\n",
    "iterations = reduce_in_tests(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_dataset, info = tfds.load(\n",
    "    name=\"mnist\", split=tfds.Split.TRAIN, with_info=True\n",
    ")\n",
    "total_num_data = info.splits[\"train\"].num_examples\n",
    "image_shape = info.features[\"image\"].shape\n",
    "image_size = tf.reduce_prod(image_shape)\n",
    "batch_size = 32\n",
    "\n",
    "\n",
    "def map_fn(input_slice: Dict[str, tf.Tensor]):\n",
    "    updated = input_slice\n",
    "    image = to_default_float(updated[\"image\"]) / 255.0\n",
    "    label = to_default_float(updated[\"label\"])\n",
    "    return tf.reshape(image, [-1, image_size]), label\n",
    "\n",
    "\n",
    "autotune = tf.data.experimental.AUTOTUNE\n",
    "dataset = (\n",
    "    original_dataset.shuffle(1024)\n",
    "    .batch(batch_size, drop_remainder=True)\n",
    "    .map(map_fn, num_parallel_calls=autotune)\n",
    "    .prefetch(autotune)\n",
    "    .repeat()\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28, 1)\n",
      "784\n"
     ]
    }
   ],
   "source": [
    "print(image_shape)\n",
    "print( int(tf.reduce_prod(image_shape)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KernelWithConvNN(gpflow.kernels.Kernel):\n",
    "    def __init__(\n",
    "        self,\n",
    "        image_shape: Tuple,\n",
    "        output_dim: int,\n",
    "        base_kernel: gpflow.kernels.Kernel,\n",
    "        batch_size: Optional[int] = None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        with self.name_scope:\n",
    "            self.base_kernel = base_kernel\n",
    "            input_size = int(tf.reduce_prod(image_shape))\n",
    "            input_shape = (input_size,)\n",
    "\n",
    "            self.cnn = tf.keras.Sequential(\n",
    "                [\n",
    "                    tf.keras.layers.InputLayer(\n",
    "                        input_shape=input_shape, batch_size=batch_size\n",
    "                    ),\n",
    "                    tf.keras.layers.Reshape(image_shape),\n",
    "                    tf.keras.layers.Conv2D(\n",
    "                        filters=32,\n",
    "                        kernel_size=image_shape[:-1],\n",
    "                        padding=\"same\",\n",
    "                        activation=\"relu\",\n",
    "                    ),\n",
    "                    tf.keras.layers.MaxPool2D(pool_size=(2, 2), strides=2),\n",
    "                    tf.keras.layers.Conv2D(\n",
    "                        filters=64,\n",
    "                        kernel_size=(5, 5),\n",
    "                        padding=\"same\",\n",
    "                        activation=\"relu\",\n",
    "                    ),\n",
    "                    tf.keras.layers.MaxPool2D(pool_size=(2, 2), strides=2),\n",
    "                    tf.keras.layers.Flatten(),\n",
    "                    tf.keras.layers.Dense(output_dim, activation=\"relu\"),\n",
    "                    tf.keras.layers.Lambda(to_default_float),\n",
    "                ]\n",
    "            )\n",
    "\n",
    "            self.cnn.build()\n",
    "\n",
    "    def K(\n",
    "        self, a_input: tf.Tensor, b_input: Optional[tf.Tensor] = None\n",
    "    ) -> tf.Tensor:\n",
    "        transformed_a = self.cnn(a_input)\n",
    "        transformed_b = self.cnn(b_input) if b_input is not None else b_input\n",
    "        return self.base_kernel.K(transformed_a, transformed_b)\n",
    "\n",
    "    def K_diag(self, a_input: tf.Tensor) -> tf.Tensor:\n",
    "        transformed_a = self.cnn(a_input)\n",
    "        return self.base_kernel.K_diag(transformed_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KernelSpaceInducingPoints(gpflow.inducing_variables.InducingPoints):\n",
    "    pass\n",
    "\n",
    "\n",
    "@gpflow.covariances.Kuu.register(KernelSpaceInducingPoints, KernelWithConvNN)\n",
    "def Kuu(inducing_variable, kernel, jitter=None):\n",
    "    func = gpflow.covariances.Kuu.dispatch(\n",
    "        gpflow.inducing_variables.InducingPoints, gpflow.kernels.Kernel\n",
    "    )\n",
    "    return func(inducing_variable, kernel.base_kernel, jitter=jitter)\n",
    "\n",
    "\n",
    "@gpflow.covariances.Kuf.register(\n",
    "    KernelSpaceInducingPoints, KernelWithConvNN, object\n",
    ")\n",
    "def Kuf(inducing_variable, kernel, a_input):\n",
    "    return kernel.base_kernel(inducing_variable.Z, kernel.cnn(a_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-28 14:45:05.662563: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-03-28 14:45:06.424475: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:433] Could not create cudnn handle: CUDNN_STATUS_NOT_INITIALIZED\n",
      "2023-03-28 14:45:06.424740: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Possibly insufficient driver version: 525.60.11\n",
      "2023-03-28 14:45:06.424772: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at conv_ops.cc:1152 : UNIMPLEMENTED: DNN library is not found.\n"
     ]
    },
    {
     "ename": "UnimplementedError",
     "evalue": "Exception encountered when calling layer \"conv2d\" \"                 f\"(type Conv2D).\n\n{{function_node __wrapped__Conv2D_device_/job:localhost/replica:0/task:0/device:GPU:0}} DNN library is not found. [Op:Conv2D]\n\nCall arguments received by layer \"conv2d\" \"                 f\"(type Conv2D):\n  • inputs=tf.Tensor(shape=(100, 28, 28, 1), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnimplementedError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m/home/schobs/Documents/PhD/local_LaNNU-Net/LaNNU-Net/models/gp_models/testing.ipynb Cell 5\u001b[0m in \u001b[0;36m<cell line: 20>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/schobs/Documents/PhD/local_LaNNU-Net/LaNNU-Net/models/gp_models/testing.ipynb#W4sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m likelihood \u001b[39m=\u001b[39m gpflow\u001b[39m.\u001b[39mlikelihoods\u001b[39m.\u001b[39mMultiClass(num_mnist_classes)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/schobs/Documents/PhD/local_LaNNU-Net/LaNNU-Net/models/gp_models/testing.ipynb#W4sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m inducing_variable_kmeans \u001b[39m=\u001b[39m kmeans2(\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/schobs/Documents/PhD/local_LaNNU-Net/LaNNU-Net/models/gp_models/testing.ipynb#W4sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     images_subset\u001b[39m.\u001b[39mnumpy(), num_inducing_points, minit\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpoints\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/schobs/Documents/PhD/local_LaNNU-Net/LaNNU-Net/models/gp_models/testing.ipynb#W4sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m )[\u001b[39m0\u001b[39m]\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/schobs/Documents/PhD/local_LaNNU-Net/LaNNU-Net/models/gp_models/testing.ipynb#W4sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m inducing_variable_cnn \u001b[39m=\u001b[39m kernel\u001b[39m.\u001b[39;49mcnn(inducing_variable_kmeans)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/schobs/Documents/PhD/local_LaNNU-Net/LaNNU-Net/models/gp_models/testing.ipynb#W4sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m inducing_variable \u001b[39m=\u001b[39m KernelSpaceInducingPoints(inducing_variable_cnn)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/schobs/Documents/PhD/local_LaNNU-Net/LaNNU-Net/models/gp_models/testing.ipynb#W4sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m model \u001b[39m=\u001b[39m gpflow\u001b[39m.\u001b[39mmodels\u001b[39m.\u001b[39mSVGP(\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/schobs/Documents/PhD/local_LaNNU-Net/LaNNU-Net/models/gp_models/testing.ipynb#W4sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     kernel,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/schobs/Documents/PhD/local_LaNNU-Net/LaNNU-Net/models/gp_models/testing.ipynb#W4sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     likelihood,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/schobs/Documents/PhD/local_LaNNU-Net/LaNNU-Net/models/gp_models/testing.ipynb#W4sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m     num_latent_gps\u001b[39m=\u001b[39mnum_mnist_classes,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/schobs/Documents/PhD/local_LaNNU-Net/LaNNU-Net/models/gp_models/testing.ipynb#W4sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m )\n",
      "File \u001b[0;32m~/.conda/envs/gpflow/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.conda/envs/gpflow/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:7215\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   7213\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mraise_from_not_ok_status\u001b[39m(e, name):\n\u001b[1;32m   7214\u001b[0m   e\u001b[39m.\u001b[39mmessage \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39m name: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m name \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 7215\u001b[0m   \u001b[39mraise\u001b[39;00m core\u001b[39m.\u001b[39m_status_to_exception(e) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n",
      "\u001b[0;31mUnimplementedError\u001b[0m: Exception encountered when calling layer \"conv2d\" \"                 f\"(type Conv2D).\n\n{{function_node __wrapped__Conv2D_device_/job:localhost/replica:0/task:0/device:GPU:0}} DNN library is not found. [Op:Conv2D]\n\nCall arguments received by layer \"conv2d\" \"                 f\"(type Conv2D):\n  • inputs=tf.Tensor(shape=(100, 28, 28, 1), dtype=float32)"
     ]
    }
   ],
   "source": [
    "num_mnist_classes = 10\n",
    "output_dim = 5\n",
    "num_inducing_points = 100\n",
    "images_subset, labels_subset = next(iter(dataset.batch(32)))\n",
    "images_subset = tf.reshape(images_subset, [-1, image_size])\n",
    "labels_subset = tf.reshape(labels_subset, [-1, 1])\n",
    "\n",
    "kernel = KernelWithConvNN(\n",
    "    image_shape,\n",
    "    output_dim,\n",
    "    gpflow.kernels.SquaredExponential(),\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "\n",
    "likelihood = gpflow.likelihoods.MultiClass(num_mnist_classes)\n",
    "\n",
    "inducing_variable_kmeans = kmeans2(\n",
    "    images_subset.numpy(), num_inducing_points, minit=\"points\"\n",
    ")[0]\n",
    "inducing_variable_cnn = kernel.cnn(inducing_variable_kmeans)\n",
    "inducing_variable = KernelSpaceInducingPoints(inducing_variable_cnn)\n",
    "\n",
    "model = gpflow.models.SVGP(\n",
    "    kernel,\n",
    "    likelihood,\n",
    "    inducing_variable=inducing_variable,\n",
    "    num_data=total_num_data,\n",
    "    num_latent_gps=num_mnist_classes,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 32, 784)\n",
      "(1024, 784)\n",
      "tf.Tensor(784, shape=(), dtype=int32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-28 14:51:22.508061: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "images_subset, labels_subset = next(iter(dataset.batch(32)))\n",
    "print(images_subset.shape)\n",
    "images_subset = tf.reshape(images_subset, [-1, image_size])\n",
    "print(images_subset.shape)\n",
    "print(image_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 784)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/schobs/Documents/PhD/local_LaNNU-Net/LaNNU-Net/models/gp_models/testing.ipynb Cell 8\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/schobs/Documents/PhD/local_LaNNU-Net/LaNNU-Net/models/gp_models/testing.ipynb#W5sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mprint\u001b[39m(x\u001b[39m.\u001b[39mshape)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/schobs/Documents/PhD/local_LaNNU-Net/LaNNU-Net/models/gp_models/testing.ipynb#W5sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m adam_opt \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39moptimizers\u001b[39m.\u001b[39mAdam(\u001b[39m0.001\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/schobs/Documents/PhD/local_LaNNU-Net/LaNNU-Net/models/gp_models/testing.ipynb#W5sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m training_loss \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mtraining_loss_closure(data_iterator)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/schobs/Documents/PhD/local_LaNNU-Net/LaNNU-Net/models/gp_models/testing.ipynb#W5sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m@tf\u001b[39m\u001b[39m.\u001b[39mfunction\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/schobs/Documents/PhD/local_LaNNU-Net/LaNNU-Net/models/gp_models/testing.ipynb#W5sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39moptimization_step\u001b[39m():\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/schobs/Documents/PhD/local_LaNNU-Net/LaNNU-Net/models/gp_models/testing.ipynb#W5sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     adam_opt\u001b[39m.\u001b[39mminimize(training_loss, var_list\u001b[39m=\u001b[39mmodel\u001b[39m.\u001b[39mtrainable_variables)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "data_iterator = iter(dataset)\n",
    "\n",
    "x, y = next(data_iterator)\n",
    "adam_opt = tf.optimizers.Adam(0.001)\n",
    "\n",
    "training_loss = model.training_loss_closure(data_iterator)\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def optimization_step():\n",
    "    adam_opt.minimize(training_loss, var_list=model.trainable_variables)\n",
    "\n",
    "\n",
    "for _ in range(iterations):\n",
    "    optimization_step()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m, v = model.predict_y(images_subset)\n",
    "preds = np.argmax(m, 1).reshape(labels_subset.numpy().shape)\n",
    "correct = preds == labels_subset.numpy().astype(int)\n",
    "acc = np.average(correct.astype(float)) * 100.0\n",
    "\n",
    "print(\"Accuracy is {:.4f}%\".format(acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
